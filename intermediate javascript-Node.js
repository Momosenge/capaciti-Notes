History of Node.js
-> Node.js is like a special tool that helps people use JavaScript in a really cool way. It has been around for a long time, even before you were born! It started in 2009 by someone named Ryan Doll. They made it work with a special engine called Chrome's VA.
In 2011, something important happened. They made a special manager called npm 1.0. It helped people share their code with others. This made it easier for everyone to work together and make cool things with Node.js. In 2015, some big companies like IBM, Microsoft, and PayPal joined together to make sure Node.js keeps growing and getting better. They formed a group called the Node.js Foundation. They work together to make sure Node.js is used in lots of different places and helps lots of people. People who use Node.js are really happy. They have big meetings and events all over the world to talk about it. It's used in many different industries to do all sorts of amazing things.

Introduction to Node.js
If you've used JavaScript before, you might think it's mainly for making websites look cool with buttons and menus. But guess what? JavaScript can do much more than that! With something called Node.js, we can use our JavaScript skills to do all sorts of different things, like making tools for the computer and creating servers to talk to other computers. Node.js has been around since 2009 and big companies like PayPal, Netflix, and Microsoft use it to make their programs work really well. In this course, we'll learn about the important parts of Node.js, like how to read and write information, how to organize our code, and how to work with files. We'll also show you examples that you can use in real life. So get ready to have fun and learn some cool stuff with Node.js!

JavaScript and Node
->In the world of making websites, we often use JavaScript to create different parts that people can see and interact with. It's really helpful when we can use the same language for both the front-end (what people see) and the back-end (the behind-the-scenes stuff). This makes things easier because we don't have to worry about differences in how the code looks or works.

Let me give you an example from my own experience. I used to work with two different languages, C# and JavaScript. Switching between them was a bit tricky because they have different ways of writing code. But when we use the same language for both front-end and back-end, we can share code and data structures seamlessly. This means we can use the same functions and tools on both sides. For example, imagine we're building a system where users need to log in with tokens. If we use the same token and encryption library on both the front-end and back-end, it ensures that the authorization process works consistently. Or let's say we're making a web game where we need to check if someone is cheating. By using the same algorithms on both sides, we can make sure everything is fair. Another situation is when we have data models, like user information with lots of properties. If we have these models in different languages, it becomes harder to maintain them. But if we use a single language for both front-end and back-end, it's much easier to make changes and keep everything organized. The key idea here is to avoid repeating ourselves and make things more efficient. When we share code and use the same language for both front-end and back-end, it makes our work easier to manage and helps us develop things faster.

Pro's of JavaScript
-> With Node.js, we can use the same language for both the back end and the front end, which makes it easier to share code between these parts. One interesting thing about JavaScript is that it determines the type of a value dynamically, not during variable declaration. This means it has loose typing instead of strong typing.

A great advantage of JavaScript is its seamless integration with JSON (JavaScript Object Notation), which is a format commonly used in web applications for both the front and back ends. Unlike other languages used in different environments, JavaScript simplifies the transfer of data from the back end to the front end without requiring complex conversions. It's important to mention that while JavaScript has many advantages, some people may see them as drawbacks in certain situations. JavaScript is not a solution that fits every scenario perfectly. However, the ability to share it between the front end and back end greatly enhances the joy of developing web applications.

Callbacks and asynchronous Tasks
-> When we perform tasks synchronously, we have to wait for each task to finish before moving on to the next one. This can cause blocking, where the program pauses until the current task is completed. An example of synchronous processing can be seen in applications where submitting a form results in a screen that appears grayed out until a response is received. This indicates a synchronous background process that hinders the responsiveness of the user interface until it's finished.

In contrast, executing tasks asynchronously allows us to move on to the next task without waiting for the previous one to complete. This is particularly useful for tasks that involve networking or accessing the file system, which often require longer waiting times, especially in web applications. Node.js excels in handling such tasks efficiently, making it a great choice for web apps. Asynchronous code often uses callbacks to manage the flow of execution. Let's take a look at a code snippet that demonstrates this. In the example, we load and read directories from drive C using Node.js. In the synchronous version, each line waits for the previous task to finish before moving on to the next one. However, in the asynchronous version, even though the "this comes after" console log appears on the last line, it is actually executed first due to the callback defined on line three. This callback is like registering a phone number for a callback in tech support. It allows the execution to continue, and the callback is triggered once the task is completed. This is similar to how the readdir function in Node.js calls our "phoneNumber" callback described on line seven.

Node globals
-> Creating a module

Let's dive into how modules work in Node.js. Start by creating a new file in Visual Studio Code and name it "my-module.js." At the same time, create another file called "module-demo.js" with the goal of making the code from "my-module.js" accessible. This showcases the power of code reuse, like using a math library across different files or projects. In the "my-module.js" file, use the exports object to make data available externally. Create a property called "myText" with a placeholder value, let's say "hello from module." Node.js has a simple module loading system that maintains a one-to-one correspondence between files and modules. To access "my-module.js," set its reference to a variable within the "module-demo.js" file using the require function. For testing purposes, use a console log to verify that the values retrieved from our module match our expectations. Run the "module-demo.js" file in the console or terminal using the command "node module-demo," and you should see the console log displaying the "hello from module" placeholder text. This demonstrates successful data access in "module-demo.js" from another module or file, and this capability can be extended to add more functionality in future stages.

Third-Party Packages
-> We have already explored how to create our own modules in Node.js, but what about using third-party modules?

Node introduces the Node Package Manager (NPM), a tool for managing packages, which are collections of one or more modules. One widely used package is Lodash. Now, let's dive into installing and utilizing it. Open your console or terminal and install Lodash by running the command "npm install lodash." After checking your directory, you will notice a new folder called "node_modules," which contains the "lodash" package with its JavaScript files providing various functionalities. With Lodash successfully installed, let's create a file for our code and name it "demo.js." Similar to our custom module, we can use the "require" function to bring in Lodash. Assign it to a variable, commonly named "_". It's important to note that we don't need to specify a location because Node automatically knows the default module location. We can use "console.log" to display the available functions. For example, we can use the "random" function to generate a random number between one and one hundred. Unlike plain JavaScript, which requires multiple calls to the math library, Lodash simplifies this process. Save the file and test it by running "node demo.js" in the console. You should see a random value printed in the console. Moving forward, there are different types of NPM packages, including those that function as command-line interfaces. Let's consider Nodemon as an example. Install it globally using the "-g" flag to ensure accessibility across projects. You will notice that Nodemon doesn't appear in the local "node_modules" folder but is available globally. Instead of using "node" to execute scripts, you can use "nodemon" to automatically run scripts whenever changes are made, enhancing development efficiency. Now, what if we install multiple third-party packages and need to keep track of their dependencies? This is where the "package.json" file comes into play. It allows us to maintain a list of installed packages and their dependencies. We will explore the significance of this file in the next step.

Package.json files
-> Currently, we are working on our project, which consists of custom files and third-party packages. However, when it comes to distributing our app or placing it in a git repository, it becomes impractical to include all the dependencies. This is due to the large amount of space they occupy and the time-consuming transfer process.

To address this issue, we can create a package.json file that maintains a list of project dependencies. When another developer wants to use our project, they can simply run the npm install command, which will automatically install all the dependencies listed in the package.json file. To create the package.json file, we can go to the terminal and enter npm init. We will be prompted with questions to answer or we can use the defaults. Once generated, the file will include the chosen defaults and scan the node_modules folder, adding the dependencies to the list. If we want to quickly create a package.json file with defaults, we can use the command npm init --yes. Now that we have covered managing modules and packages in Node.js, let's explore one of the widely used built-in modules for file read and write operations.

Node modules
-> Reading from files

In the realm of heavy input/output operations, there are two prominent areas: network and disk access. Let's focus on disk access and work with files. To get started, we will create a new file called demo.js. Now, we can gain access to the file system built within Node by requiring the 'fs' module. It's worth noting that the library is appropriately named 'fs' as well. To begin, we need a file to read from. Let's generate a temporary JSON file called data.json. Inside this file, we will create an object with a property named 'name' enclosed in double quotes, using 'Tim' as a placeholder. To access the file system, we will use the 'readFile' function, passing the location of our data JSON file as the first parameter. Since this function is asynchronous, the second parameter is a callback. Instead of using a separate function, we can use an anonymous function directly as the callback or opt for a more concise arrow function. When we execute the code, we may encounter unexpected output with a buffer at the start. This is because we haven't specified the file format. To rectify this, we can shift the callback to the third parameter and add 'UTF-8' as a string in the second parameter. This allows us to successfully read the JSON. Alternatively, we can access the JSON file directly using 'require'. By creating a variable called 'data' and setting it to 'require' with the path to data.json, we can log the data. Now, we will observe two distinct objects in our console - one from 'require' and another from 'readFile'. These objects may exhibit disparities. Testing the 'name' property reveals that the object from 'require' is a true object, whereas the object from 'readFile' is just a string. To address this, within the 'readFile' callback, we can create a new variable called 'data' and set it to 'JSON.parse(data)' to convert the string to JSON. As a result, we can access 'data.name', which will display two names in the console.

-> Directory Access

Now that we have developed a strong understanding of reading files in the file system, let's move on to exploring directory reading. To do this, we will create a new demonstration file that requires access to the file system. We can achieve this by requiring the 'fs' module and utilizing the 'readdir' function from the file system. The initial parameter for 'readdir' should specify the directory location we want to read. For the purpose of illustration, let's use Drive C as an example. Next, let's set up a callback function that accepts error and data as parameters. We can then log the data using the console. After saving the changes, we can use nodemon to execute the demo and observe the output, which will display all the directories within Drive C. This demonstrates the straightforward process of reading directories. Moving forward, let's delve into the topic of writing files.

-> Writing to Files

Now that we have become proficient in file and directory operations, our next focus is on file writing. To begin, we create a new file called demo.js and include the file system module. To write a file, we use the writeFile function, where the first parameter is the file name (in this case, data.json) and the second parameter is the data to be written. Instead of directly specifying the data, you can define a variable called 'data' as a JSON object. This object includes a 'name' property with the value 'Bob'. We then pass this data object as the second parameter to the writeFile function. When we execute the script with the command node demo.js, it generates a data.json file. However, upon inspection, we notice that the file content does not match our expectations. This discrepancy occurs because the writeFile function expects a string as the second parameter, not a JSON object. To address this, we need to convert our object to a string. While a manual approach involves enclosing everything in double quotes, a more efficient method is to use JSON.stringify. We make this modification on line seven, resulting in the desired JSON format. Although the script functions correctly, a deprecation warning occurs, advising against calling an asynchronous function without a callback. Upon further investigation, we discover that the writeFile function expects a callback as its third parameter. To resolve this, we create a callback function that logs any errors and a 'write finished' message to the console. The updated script eliminates the deprecation warning and provides feedback upon completion. Now that we have comprehensive knowledge of file system operations, our next step involves exploring popular web frameworks for Node.js.

-> Node Frameworks

Let's embark on an exploration of various Node.js frameworks for web development. First, it's crucial to grasp the concept of a framework. In simple terms, a framework serves as a foundational structure, much like the support structure of a building or vehicle. In software development, a framework provides the essential structure that developers can build upon. When it comes to web development, especially for creating large APIs or HTTP servers, utilizing web frameworks becomes essential. These frameworks offer a structured foundation and necessary components to facilitate tasks such as serving static files for traditional websites or constructing web APIs for interaction in web applications. In this context, a web API acts as a service that enables the retrieval and storage of data to and from the server or backend. For example, a web API can be used to manage user creation, retrieval, and other related functionalities. Now, let's delve into some popular web frameworks for Node.js. Express is a standout framework known for its simplicity and extensive testing. It provides a straightforward and reliable option for developers. Another notable framework is Sails, which goes beyond being a singular framework and includes sub-frameworks like an Object Relational Mapper (ORM). This feature-rich framework facilitates database access and offers additional functionalities, making it a comprehensive choice. Lastly, we have Koa, the most modern among the discussed frameworks. Koa offers a contemporary approach to web development and is worth exploring for its innovative features. In the upcoming sections, we will take a closer look at each of these frameworks - Express, Sails, and Koa - to gain a deeper understanding of their features and capabilities.

-> Express

Let us embark on an exploration of the initial web framework designed for Node by visiting expressjs.com. As we scroll down the page, we can observe that Express.js provides support for both web applications and web APIs. The term "web application" can sometimes cause confusion as to whether it refers to the front end or back end. When we think of apps, we often associate them with functionalities running in browsers or on mobile devices. However, these apps frequently need to communicate with a server for tasks such as user authentication or retrieving data for display. In essence, a web app encompasses functionalities on both the front end and back end, distributed across the entire application. Imagine platforms like Twitter without the ability to fetch tweets from the back end. Express.js, operating within Node, specifically addresses the back end. Despite its back-end nature, Express.js significantly contributes to the overall app by facilitating communication with the back end. It is worth noting that Express.js enjoys extensive community support and offers comprehensive online documentation, thanks to its longstanding presence in the development community.

-> Socket.io

Socket.io facilitates real-time, two-way, event-driven communication, which addresses a limitation in Express. Unlike Express, which only allows the client to initiate requests to the server, Socket.io enables bidirectional communication. This means that the server can push notifications and data to the client when specific events occur. The mechanism involves two parts: a client-side library for browsers and a server-side library for Node.js. Both libraries have nearly identical APIs and function in an event-driven manner, similar to Node.js. In our upcoming demonstration application, we will explore how this functionality operates. Let's proceed with creating the demo application using these frameworks.
